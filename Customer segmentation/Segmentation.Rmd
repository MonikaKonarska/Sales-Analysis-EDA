---
title: "Customer segmentation"
output: md_document
always_allow_html: yes

---
The purpose of this analysis is to identify separate groups of clients that show different shopping behaviors. Based on the available data and using some methods is possible to extract some specific customer profiles.<p>  
Customer segmentation is the process of dividing customers into groups based upon certain boundaries; clustering is one way to generate these boundaries. 
<strong><em>Algorithms selected</em></strong>: K-means, Principal Component Analysis (PCA)   


```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyr)
library(tidyverse)  
library(cluster)    
library(factoextra)
library(DT)
library(cowplot)
library(kableExtra)

options(kableExtra.html.bsTable = T)
knitr::opts_chunk$set(echo = FALSE)
set.seed(1234)
fileDataName <- "BlackFriday.csv"
pathData <- file.path(getwd(), "..", "data")
fileData <- file.path(pathData, fileDataName)
data <- read.csv(file = fileData, header = TRUE, sep = ",")
```
<br>
<br>

## <em>Data preparation to segmentation analysis</em>

The data should be prepared. In the beginning, add some new variables about the amount of purchase, product choice.<br>
The new variables are:

 - minBasket   
 - avgBasket   
 - maxBasket   
 - totalBasket   
 - nBasket   
 - the amout of purchase each product of category number one (`totalCategory1`, `totalCategory2` ...) 

The data is aggregated by the column assigned `User_ID`.
<br>
<br>

```{r prepareData, message = FALSE, warning = FALSE, echo = FALSE}
productCategory1Information <- data %>%
  filter(is.na(Product_Category_2)) %>%
  filter(is.na(Product_Category_3)) %>%
  select(User_ID, Product_Category_1, Purchase) %>%
  group_by(User_ID, Product_Category_1) %>%
  summarise(totalBasketProduct1 = sum(Purchase)) %>%
  mutate(Product_Category_1 = as.factor(Product_Category_1)) %>%
  spread(Product_Category_1, totalBasketProduct1) %>%
  replace(is.na(.), 0) %>%
  rename_if(grepl("[0-9]+", colnames(.)), funs(paste0("totalCategory", .)))

basketCustomerInformation <- data %>%
  filter(is.na(Product_Category_2)) %>%
  filter(is.na(Product_Category_3)) %>%
  select(-c("Product_ID","Product_Category_1","Product_Category_2","Product_Category_3")) %>%
  group_by(User_ID, Gender, Age, Occupation, City_Category, Stay_In_Current_City_Years, Marital_Status) %>%
  dplyr::summarise(minBasket = min(Purchase),
                   avgBasket = round(mean(Purchase),2),
                   maxBasket = max(Purchase),
                   totalBasket = sum(Purchase),
                   nBasket = n()) %>%
  left_join(productCategory1Information, by = c("User_ID" = "User_ID")) 

kable(head(basketCustomerInformation, 6)) %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "250px")
```


## <em>K-means</em>

K-means clustering is a very simple and fast algorithm. To use this popular method for customer segmentation is needed to use only numerical data. The data must be scaled.
<br>
<br>

```{r scaledData, message = FALSE, warning = FALSE, echo = FALSE}
datatoAlgorythm <- basketCustomerInformation[, which(!names(basketCustomerInformation) %in%  c("User_ID" ,"Gender", "Age", "Occupation", "City_Category","User_ID", "Stay_In_Current_City_Years", "Marital_Status"))]
datatoAlgorythmScaled <- scale(datatoAlgorythm)

kable(head(datatoAlgorythmScaled, 6)) %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "250px")
```

<br>
<br>

### <em>To define an optimal number of clusters</em>

 - Elbow method   
The elbow method looks at the percentage of variance explained as a function of the number of clusters. <br>
The second cluster will add much information (explain a lot of variances).<br>
K=3 should be a good choice for number of clusters however k=4 also seems to be a potential candidate. 
 

```{r numberClusters, message = FALSE, warning = FALSE, echo = FALSE}

optimalNumberClusterplot <- function(data, numberClusters = 15) {
  wss <- (nrow(data)- 1)*sum(apply(data, 2, var))
  for (i in 2:numberClusters) {
    set.seed(1234)
    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
  
  plot(1:numberClusters, wss, type = "b", xlab = "Number of clusters K",
       ylab="Total within-clusters sum of squares")
  }

optimalNumberClusterplot(data = datatoAlgorythmScaled, numberClusters = 15)

```
<br>
<br>

### <em>Results of analysis with 3 and 4 clusters</em> {.tabset .tabset-fade }
<br>
<br>

#### 2 clusters

```{r cluster2Information, message = FALSE, warning = FALSE, echo = FALSE}
clusters2 <- kmeans(datatoAlgorythmScaled, 2, nstart = 25)
clusters2$centers
table(clusters2$cluster)

```

#### 3 clusters

```{r cluster3Information, message = FALSE, warning = FALSE, echo = FALSE}
clusters3 <- kmeans(datatoAlgorythmScaled, 3, nstart = 25)
clusters3$centers
table(clusters3$cluster)

```

#### 4 clusters

```{r cluster4Information, message = FALSE, warning = FALSE, echo = FALSE}
clusters4 <- kmeans(datatoAlgorythmScaled, 4, nstart = 25)
clusters4$centers
table(clusters4$cluster)

```

<br>
<br>


## <em>Perform PCA to visualize the clusters</em> 
  
PCA 1 and PCA 2 combined explain the majority of the data variance and then there is a drop from PCA 2 to PCA 3.   
Including more PCAâ€™s after PCA 3 will only result in minimal improvement.


```{r clustersAndPca, message = FALSE, warning = FALSE, echo = FALSE}
pca <- prcomp(t(datatoAlgorythmScaled), scale. = T, center = T)

fviz_eig(pca) +
  theme_bw() +
  scale_y_continuous(labels = scales::comma) +
  ggtitle(label='Principal Component Analysis (PCA)')

```
 
 
 - <em>PCA with 2,3 and 4 cluster K-means</em>
 
```{r clustersPlot, message = FALSE, warning = FALSE, echo = FALSE}
clusterPc2                <- prcomp(datatoAlgorythmScaled, center = FALSE, scale. = FALSE)$x %>% as.data.frame()
clusterPc2$kmeansCluster  <- factor(clusters2$cluster)

plotClusterPc2 <- ggplot(clusterPc2, aes(x=PC1, y=PC2, color = kmeansCluster))+
  geom_point()+
  theme_bw() + scale_y_continuous(labels = scales::comma) +
  ggtitle(label='PCA with 2 cluster K-means') 

clusterPc3 <- prcomp(datatoAlgorythmScaled, center = FALSE, scale. = FALSE)$x %>% 
  as.data.frame()
clusterPc3$kmeansCluster  <- factor(clusters3$cluster)

plotClusterPc3 <- ggplot(clusterPc3, aes(x=PC1, y=PC2, color = kmeansCluster))+
  geom_point()+
  theme_bw() + scale_y_continuous(labels = scales::comma) +
  ggtitle(label='PCA with 3 cluster K-means') 

clusterPc4                <- prcomp(datatoAlgorythmScaled, center = FALSE, scale. = FALSE)$x %>% as.data.frame()
clusterPc4$kmeansCluster  <- factor(clusters4$cluster)

plotClusterPc4 <- ggplot(clusterPc4, aes(x=PC1, y=PC2, color = kmeansCluster))+
  geom_point()+
  theme_bw() + scale_y_continuous(labels = scales::comma) +
  ggtitle(label='PCA with 4 cluster K-means') 


plot_grid(plotClusterPc2, plotClusterPc3, plotClusterPc4)

```

```{r customer_clusters_plot,message = FALSE, warning = FALSE, echo = FALSE}
fviz_cluster(clusters3, data = datatoAlgorythmScaled, geom = "point", stand = FALSE, ellipse.type = "norm") + 
  theme_bw() +
  scale_y_continuous(labels = scales::comma) +
  ggtitle(label='Customer Clusters')
```

















